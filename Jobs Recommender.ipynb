{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Anaconda3\\lib\\site-packages\\gensim\\utils.py:1197: UserWarning: detected Windows; aliasing chunkize to chunkize_serial\n",
      "  warnings.warn(\"detected Windows; aliasing chunkize to chunkize_serial\")\n"
     ]
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import ast \n",
    "from scipy import stats\n",
    "from ast import literal_eval\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer, CountVectorizer\n",
    "from sklearn.metrics.pairwise import linear_kernel, cosine_similarity\n",
    "# from nltk.stem.snowball import SnowballStemmer\n",
    "# from nltk.stem.wordnet import WordNetLemmatizer\n",
    "# from nltk.corpus import wordnet\n",
    "# from surprise import Reader, Dataset, SVD, evaluate\n",
    "from gensim.models import Doc2Vec\n",
    "import gensim.models.doc2vec\n",
    "from collections import OrderedDict\n",
    "import multiprocessing\n",
    "\n",
    "from uszipcode import SearchEngine\n",
    "from  geopy.distance import distance\n",
    "\n",
    "\n",
    "MAX_DISTANCE = 15\n",
    "\n",
    "import warnings; warnings.simplefilter('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert gensim.models.doc2vec.FAST_VERSION > -1, \"This will be painfully slow otherwise\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#!dir .\\Data\\*.tsv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "b'Skipping line 122433: expected 11 fields, saw 12\\n'\n",
      "b'Skipping line 602576: expected 11 fields, saw 12\\n'\n",
      "b'Skipping line 990950: expected 11 fields, saw 12\\n'\n"
     ]
    }
   ],
   "source": [
    "folder = 'Data'\n",
    "\n",
    "apps = pd.read_csv('./'+folder+'/apps.tsv', delimiter='\\t',encoding='utf-8')\n",
    "user_history = pd.read_csv('./'+folder+'/user_history.tsv', delimiter='\\t',encoding='utf-8')\n",
    "jobs = pd.read_csv('./'+folder+'/jobs.tsv', delimiter='\\t',encoding='utf-8', error_bad_lines=False)\n",
    "users = pd.read_csv('./'+folder+'/users.tsv' ,delimiter='\\t',encoding='utf-8')\n",
    "test_users = pd.read_csv('./'+folder+'/test_users.tsv', delimiter='\\t',encoding='utf-8')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### EDA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "apps.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "user_history.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "jobs.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "users.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_users.head()\n",
    "len(users)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "users = users.loc[users.State == 'NY']\n",
    "len(users)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "users = users.sample(frac=0.2, replace=False, random_state=1)\n",
    "len(users)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Subsetting jobs in NY"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "jobs = jobs.loc[jobs.State == 'NY']\n",
    "\n",
    "#jobs.to_csv(\"NYjobs.tsv\",  sep='\\t',encoding='utf-8')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Subsetting jobs in Zip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "jobs.Zip5 = jobs.Zip5.fillna(0)\n",
    "jobs.Zip5 = jobs.Zip5.astype(int)\n",
    "jobs = jobs.loc[jobs['Zip5'] != 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "jobs = jobs.sample(frac=0.2, replace=False, random_state=1)\n",
    "len(jobs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gc\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "jobs.groupby(['Zip5', 'City']).size().reset_index(name='Count').sort_values('Count', ascending=False).head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preprocessing Description and Requirements"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "def preprocessor(text):\n",
    "    text = text.replace('\\\\r', '').replace('&nbsp', '').replace('\\n', '')\n",
    "    text = re.sub('<[^>]*>', '', text)\n",
    "    emoticons = re.findall('(?::|;|=)(?:-)?(?:\\)|\\(|D|P)', text)\n",
    "    text = re.sub('[\\W]+', ' ', text.lower()) +\\\n",
    "        ' '.join(emoticons).replace('-', '')\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "jobs['Description'] = jobs['Description'].astype(dtype='str').apply(preprocessor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "jobs['Requirements'] = jobs['Requirements'].astype(dtype='str').apply(preprocessor)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creating jobs coordinates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "search = SearchEngine(simple_zipcode=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#lat, \"long\"\n",
    "\"\"\"coords_1 = c\n",
    "coords_2 = (34.1, -118.42)\n",
    "\n",
    "print (round(distance(coords_1, coords_2).miles, 2))\"\"\"\n",
    "search.by_zipcode(\"2e\").lat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def coordinates(zipcode):\n",
    "    zipcode = search.by_zipcode(zipcode)\n",
    "    community = zipcode.post_office_city\n",
    "    return community, \"{},{}\".format(zipcode.lat, zipcode.lng)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%timeit\n",
    "jobs[\"Community\"] = \"\"\n",
    "jobs[\"Coordinates\"] = \"\"\n",
    "for zipcode in jobs.Zip5.unique():\n",
    "    community, coordinate = coordinates(zipcode)\n",
    "    jobs.loc[jobs.Zip5 == zipcode, \"Coordinates\"] =  str(coordinate)\n",
    "    jobs.loc[jobs.Zip5 == zipcode, \"Community\"] =  community"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "jobs.groupby(['Community']).size().reset_index(name='Count').sort_values('Count', ascending=False).head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "jobs.groupby(['Community', 'Zip5', 'Coordinates']).size().reset_index(name='Count').sort_values('Count', ascending=False).head(20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### creating user coordinates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def creating_coordinates(df, column):\n",
    "    df[\"Community\"] = \"\"\n",
    "    df[\"Coordinates\"] = \"None, None\"\n",
    "    for zipcode in df[column].unique():\n",
    "        community, coordinate = coordinates(zipcode)\n",
    "        df.loc[df[column] == zipcode, \"Coordinates\"] =  str(coordinate)\n",
    "        df.loc[df[column] == zipcode, \"Community\"] =  community\n",
    "    return df\n",
    "users = creating_coordinates(users, 'ZipCode')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "users.groupby(['Community']).size().reset_index(name='Count').sort_values('Count', ascending=False).head(20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Distance Matrix "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "users.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "jobs.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "apps.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "user_history.head(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Subset most applied jobs by title"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Looking similar jobs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "current_app_intercep = np.intersect1d(users.UserID.unique(), apps.UserID.unique())\n",
    "historical_app_intercep = np.intersect1d(users.UserID.unique(), user_history.UserID.unique())\n",
    "total_users = users.UserID.unique()\n",
    "with_info =  set(current_app_intercep.tolist() + historical_app_intercep.tolist())\n",
    "\n",
    "current_app = 1-len(current_app_intercep )/len(total_users )\n",
    "historical_app = 1-len(historical_app_intercep)/ len(total_users )\n",
    "cold_star_p = len(with_info)/len(total_users )\n",
    "\n",
    "print(current_app, historical_app, cold_star_p)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#distance_jobs_df = pd.DataFrame(columns=jobs.JobID.unique(), index = users.index)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Looks for most applied jobs id"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Distance matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "#distance_jobs_df = pd.DataFrame(columns=jobs.JobID.unique(), index = users.index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "#distance_jobs_df.to_csv()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Recomender top k liked"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def user_exist(user):\n",
    "    if len(users.loc[users['UserID'] == user]) == 0:\n",
    "        return False\n",
    "    return True\n",
    "\n",
    "def has_coordinates(user):\n",
    "    if len(users.loc[users['UserID'] == user, \"Coordinates\"]) == 0:\n",
    "        return False\n",
    "    return True\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "unique = 0.3 #update name\n",
    "top = 20\n",
    "\n",
    "def ranking_by_popularity(top):\n",
    "    \n",
    "    popular_jobs = user_history.groupby(\n",
    "    ['JobTitle']).size().reset_index(\n",
    "    name='Count').sort_values('Count', ascending=False)\n",
    "    ranking =  dict()\n",
    "    top_i = 0\n",
    "    \n",
    "    while True:\n",
    "        job_title = popular_jobs['JobTitle'].iloc[top_i]\n",
    "        jobs_list = jobs.loc[jobs['Title'] == job_title, ['JobID']]['JobID'].unique().tolist()\n",
    "\n",
    "        if len(jobs_list) > 1:\n",
    "            ranking[job_title] = jobs_list\n",
    "\n",
    "        if len(ranking) == top:\n",
    "            break\n",
    "\n",
    "        top_i +=1\n",
    "    return ranking\n",
    "\n",
    "ranking_popular = ranking_by_popularity(top)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def recommender_popular_jobs(user, unique, top):\n",
    "    \n",
    "    recommended_popular_jobs = dict()\n",
    "    c1 = users.loc[users['UserID'] == user, 'Coordinates']\n",
    "    \n",
    "    if user_exist(user) and has_coordinates(user):\n",
    "        for title, jobs_list in ranking_popular.items():\n",
    "            \n",
    "            distances = dict()\n",
    "            \n",
    "            for job in jobs_list:\n",
    "                \n",
    "                c2 = jobs.loc[jobs['JobID'] == job, 'Coordinates']\n",
    "                if c2.iloc[0].split(',')[0] == 'None':\n",
    "                    continue\n",
    "                distances[job] = round(distance(c1, c2).miles, 2)\n",
    "            \n",
    "            distances = sorted(distances.items(), key=lambda kv: kv[1])\n",
    "            closest = distances[0]\n",
    "            if closest[1] >= MAX_DISTANCE:\n",
    "                continue\n",
    "            recommended_popular_jobs[title] = (closest[0], closest[1])\n",
    "            \n",
    "    else:\n",
    "        for title, jobs_list in ranking_popular.items():\n",
    "            recommended_popular_jobs[title] = jobs_list[0]\n",
    "            \n",
    "    return recommended_popular_jobs\n",
    "\n",
    "recommender_popular_jobs(98, unique, top)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Content Based title x profile\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "jobs['profile'] = jobs['Title'].astype(str)  +  '. ' + jobs['Requirements'].astype(str) +  '. ' + jobs['Description'].astype(str) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%timeit\n",
    "\n",
    "users['profile'] = (users['DegreeType'].astype(str) + \" \")*5 + (users['Major'].astype(str) +  \" \" )*5\n",
    "#+ \" Years of Experience \" + users['TotalYearsExperience'].astype(str)\n",
    "#+ str(p.number_to_words(users[\"TotalYearsExperience\"])) + \" Years of Experience \" + \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Garbage words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "users['profile'] = users['profile'].str.replace('None.', '.')\n",
    "users['profile'] = users['profile'].str.replace('Not Applicable', '.')\n",
    "users['profile'] = users['profile'].str.replace(' nan', ' ') \n",
    "\n",
    "users['profile'].iloc[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gensim.models.doc2vec import Doc2Vec, TaggedDocument\n",
    "from gensim.utils import simple_preprocess\n",
    "from gensim.test.utils import get_tmpfile\n",
    "from gensim.models.callbacks import CallbackAny2Vec\n",
    "\n",
    "import pickle\n",
    "\n",
    "simple_preprocess(users['profile'].iloc[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class EpochLogger(CallbackAny2Vec):\n",
    "    '''Callback to log information about training'''\n",
    "\n",
    "    def __init__(self):\n",
    "        self.epoch = 0\n",
    "\n",
    "    def on_epoch_begin(self, model):\n",
    "        print(\"Epoch #{} start\".format(self.epoch))\n",
    "        self.epoch += 1\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "jobs['Coordinates']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#If user has coordinates\n",
    "#if user has info then similarties if not popularity ranker\n",
    "\n",
    "\n",
    "def content_distance_based_recommender(user_id, jobID_mapping = jobID_mapping, model =  model, top = 10):\n",
    "    #As infer_vector produce stochastics result I made a for to save the best list\n",
    "    user_profile = np.array(users.loc[users['UserID'] == user_id, 'profile'])[0]\n",
    "    historical_apps = user_history.loc[user_history.UserID == user_id, 'JobTitle']\n",
    "    for application in historical_apps:\n",
    "        user_profile += \". \" + (str(application) + \" \")*10\n",
    "    user_profile = simple_preprocess(user_profile)\n",
    "    \n",
    "    best = 0\n",
    "    top10=pd.DataFrame(index = range(top), columns = ['JobID', 'Title', 'Distance', 'Description', 'Requirements'])\n",
    "    c1 = users.loc[users['UserID'] == user_id, 'Coordinates']\n",
    "    job_distance_list = list()\n",
    "    for i in range (5):\n",
    "        inferred_vector = model.infer_vector(user_profile)\n",
    "        sims = model.docvecs.most_similar([inferred_vector], topn=len(model.docvecs))\n",
    "        sum_results = 0\n",
    "        count = 0\n",
    "        total_recom = 0\n",
    "        job_distance_list = list()\n",
    "        \n",
    "        while True:\n",
    "            \n",
    "            c2 = jobs.loc[jobs['JobID'] == sims[count][0], 'Coordinates']\n",
    "            count +=1\n",
    "            if len(c2) == 0:\n",
    "                print(\"Empy\")\n",
    "                continue\n",
    "            \n",
    "            if c2.iloc[0].split(',')[0] == 'None':\n",
    "                print('None')\n",
    "                continue\n",
    "                \n",
    "            job_distance = round(distance(c1, c2).miles, 2)\n",
    "            \n",
    "            if job_distance >= MAX_DISTANCE:\n",
    "                print('Distance')\n",
    "                continue\n",
    "\n",
    "            sum_results+=sims[count][1]\n",
    "            total_recom +=1\n",
    "            job_distance_list.append(job_distance)\n",
    "            if total_recom == top:\n",
    "                break\n",
    "        \n",
    "        ##Best simulation\n",
    "        if sum_results > best:\n",
    "            best = sum_results\n",
    "            best_sim = sims\n",
    "            job_distance_list2 = job_distance_list\n",
    "        print(count)\n",
    "\n",
    "            \n",
    "            \n",
    "    for i in range(top):\n",
    "        recomendation = jobID_mapping[best_sim[i][0]]\n",
    "        top10.iloc[i]['JobID', 'Title',  'Description', 'Requirements'] = np.array(jobs.loc[jobs['JobID'] == recomendation][['JobID', 'Title', \n",
    "                                                               'Description', 'Requirements']])[0]\n",
    "        top10.iloc[i]['Distance'] = job_distance_list2[i]\n",
    "    \n",
    "    return top10, sims    \n",
    "\n",
    "\n",
    "t, s = content_distance_based_recommender(user_id, top=15)    \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1070,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>JobID</th>\n",
       "      <th>Title</th>\n",
       "      <th>Distance</th>\n",
       "      <th>Description</th>\n",
       "      <th>Requirements</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1080071</td>\n",
       "      <td>ADMINISTRATIVE/CLERICAL</td>\n",
       "      <td>13.28</td>\n",
       "      <td>colating</td>\n",
       "      <td>nan</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>244585</td>\n",
       "      <td>Assistant Produce Manager</td>\n",
       "      <td>1.9</td>\n",
       "      <td>know how to put the super in supermarket at ha...</td>\n",
       "      <td>here is that you will need to bring to the pos...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>549641</td>\n",
       "      <td>ADMINISTRATIVE/CLERICAL</td>\n",
       "      <td>2.07</td>\n",
       "      <td>colating</td>\n",
       "      <td>nan</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>563550</td>\n",
       "      <td>Executive Administrator</td>\n",
       "      <td>1.38</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1101142</td>\n",
       "      <td>Licensing Associate-Hiring Event 6/6!!</td>\n",
       "      <td>1.38</td>\n",
       "      <td>we are currently looking for a licensing assoc...</td>\n",
       "      <td>four year degree in business administration f...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>897408</td>\n",
       "      <td>Manager - Employee Relations</td>\n",
       "      <td>1.38</td>\n",
       "      <td>the employee relations manager serves as a key...</td>\n",
       "      <td>bachelor s or graduate degree in human resour...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>1114193</td>\n",
       "      <td>Internal Auditor</td>\n",
       "      <td>2.07</td>\n",
       "      <td>internal auditor top woodbury firm seeks indiv...</td>\n",
       "      <td>minimum 3 years experience</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>731174</td>\n",
       "      <td>Mortgage Support: 2nd Shift 3-12</td>\n",
       "      <td>9.81</td>\n",
       "      <td>ost professional a division of open systems te...</td>\n",
       "      <td>if you meet the following qualifications pleas...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>1051392</td>\n",
       "      <td>Financial Sales Professional- Entry Level or E...</td>\n",
       "      <td>0.69</td>\n",
       "      <td>join axa ndash the axa group is listed in the...</td>\n",
       "      <td>job requirements individuals who excel at axa ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>708253</td>\n",
       "      <td>Risk Management Account Management - NY</td>\n",
       "      <td>0.52</td>\n",
       "      <td>large national company is seeking an account m...</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>1062879</td>\n",
       "      <td>Lega; Recep/ Office Support Administrator- Cla...</td>\n",
       "      <td>2.07</td>\n",
       "      <td>position summary due to the critical impact o...</td>\n",
       "      <td>education and work experience 3 years of relat...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>1062881</td>\n",
       "      <td>Lega; Recep/ Office Support Administrator- Cla...</td>\n",
       "      <td>3.74</td>\n",
       "      <td>position summary due to the critical impact o...</td>\n",
       "      <td>education and work experience 3 years of relat...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>767261</td>\n",
       "      <td>Downtown financial services firm seeks experie...</td>\n",
       "      <td>1.38</td>\n",
       "      <td>classification secretary admin asst n ncompens...</td>\n",
       "      <td>as an executive assistant at this firm previou...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>23913</td>\n",
       "      <td>Accounting Specialist</td>\n",
       "      <td>1.38</td>\n",
       "      <td>superior staff resources is currently recruiti...</td>\n",
       "      <td>required skills qualifications nminimum of 2 y...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>260187</td>\n",
       "      <td>Compliance Consultant</td>\n",
       "      <td>1.38</td>\n",
       "      <td>compliance consultants maintain the authority ...</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      JobID                                              Title Distance  \\\n",
       "0   1080071                            ADMINISTRATIVE/CLERICAL    13.28   \n",
       "1    244585                          Assistant Produce Manager      1.9   \n",
       "2    549641                            ADMINISTRATIVE/CLERICAL     2.07   \n",
       "3    563550                            Executive Administrator     1.38   \n",
       "4   1101142             Licensing Associate-Hiring Event 6/6!!     1.38   \n",
       "5    897408                       Manager - Employee Relations     1.38   \n",
       "6   1114193                                   Internal Auditor     2.07   \n",
       "7    731174                   Mortgage Support: 2nd Shift 3-12     9.81   \n",
       "8   1051392  Financial Sales Professional- Entry Level or E...     0.69   \n",
       "9    708253            Risk Management Account Management - NY     0.52   \n",
       "10  1062879  Lega; Recep/ Office Support Administrator- Cla...     2.07   \n",
       "11  1062881  Lega; Recep/ Office Support Administrator- Cla...     3.74   \n",
       "12   767261  Downtown financial services firm seeks experie...     1.38   \n",
       "13    23913                              Accounting Specialist     1.38   \n",
       "14   260187                              Compliance Consultant     1.38   \n",
       "\n",
       "                                          Description  \\\n",
       "0                                            colating   \n",
       "1   know how to put the super in supermarket at ha...   \n",
       "2                                            colating   \n",
       "3                                                       \n",
       "4   we are currently looking for a licensing assoc...   \n",
       "5   the employee relations manager serves as a key...   \n",
       "6   internal auditor top woodbury firm seeks indiv...   \n",
       "7   ost professional a division of open systems te...   \n",
       "8    join axa ndash the axa group is listed in the...   \n",
       "9   large national company is seeking an account m...   \n",
       "10   position summary due to the critical impact o...   \n",
       "11   position summary due to the critical impact o...   \n",
       "12  classification secretary admin asst n ncompens...   \n",
       "13  superior staff resources is currently recruiti...   \n",
       "14  compliance consultants maintain the authority ...   \n",
       "\n",
       "                                         Requirements  \n",
       "0                                                 nan  \n",
       "1   here is that you will need to bring to the pos...  \n",
       "2                                                 nan  \n",
       "3                                                      \n",
       "4    four year degree in business administration f...  \n",
       "5    bachelor s or graduate degree in human resour...  \n",
       "6                         minimum 3 years experience   \n",
       "7   if you meet the following qualifications pleas...  \n",
       "8   job requirements individuals who excel at axa ...  \n",
       "9                                                      \n",
       "10  education and work experience 3 years of relat...  \n",
       "11  education and work experience 3 years of relat...  \n",
       "12  as an executive assistant at this firm previou...  \n",
       "13  required skills qualifications nminimum of 2 y...  \n",
       "14                                                     "
      ]
     },
     "execution_count": 1070,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1038,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch #0 start\n",
      "Epoch #1 start\n",
      "Epoch #2 start\n",
      "Epoch #3 start\n",
      "Epoch #4 start\n",
      "Wall time: 20.6 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "def similarities_nlp_model( model_name = \"jobs_doc2vec_model_3\",\n",
    "                 mapping_name = \"jobID_mapping_3.p\", max_epochs = 100,\n",
    "                 alpha = 0.025):\n",
    "    \n",
    "    document = list()\n",
    "    jobID_mapping = dict()\n",
    "        \n",
    "    for i, token in enumerate(jobs['profile']):\n",
    "        value = jobs.iloc[i][\"JobID\"]\n",
    "        tokens = TaggedDocument(simple_preprocess(token), [i])\n",
    "        document.append(tokens)\n",
    "        jobID_mapping[i] = value\n",
    "        print(i)\n",
    "\n",
    "    epoch_logger = EpochLogger()\n",
    "    model = Doc2Vec(size = 20, alpha=alpha, \n",
    "                    min_alpha=0.00025, min_count=1,\n",
    "                    callbacks=[epoch_logger], dm =1, workers=8\n",
    "                   )\n",
    "    \n",
    "    model.build_vocab(document)\n",
    "    \n",
    "    for epoch in range(max_epochs):\n",
    "        print('iteration {0}'.format(epoch))\n",
    "        model.train(document, \n",
    "                    total_examples=model.corpus_count, \n",
    "                    epochs=model.iter)\n",
    "        # decrease the learning rate\n",
    "        model.alpha -= 0.0002\n",
    "        # fix the learning rate, no decay\n",
    "        model.min_alpha = model.alpha\n",
    "\n",
    "    # create a dictionary\n",
    "    pickle.dump(model, open(model_name, \"wb\")) \n",
    "    pickle.dump(jobID_mapping, open(mapping_name, \"wb\")) \n",
    "\n",
    "# -------------------------------------------------------------\n",
    "# Load the dictionary back from the pickle file.\n",
    "    return model, jobID_mapping\n",
    "\n",
    "model, jobID_mapping = similarities_nlp_model()\n",
    "jobID_mapping = pickle.load(open(\"jobID_mapping.p\", \"rb\"))\n",
    "model  = pickle.load(open(\"jobs_doc2vec_model\", \"rb\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1035,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<gensim.models.doc2vec.Doc2Vec at 0x278ac508c88>"
      ]
     },
     "execution_count": 1035,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "jobID_mapping = pickle.load(open(\"jobID_mapping.p\", \"rb\"))\n",
    "model  = pickle.load(open(\"jobs_doc2vec_model\", \"rb\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1042,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#jobID_mapping = pickle.load(open(\"jobID_mapping.p\", \"rb\"))\n",
    "#model  = pickle.load(open(\"jobs_doc2vec_model\", \"rb\"))\n",
    "\n",
    "def content_based_recommender(user_id, jobID_mapping = jobID_mapping, model =  model, top = 100):\n",
    "    #As infer_vector produce stochastics result I made a for to save the best list\n",
    "    user_profile = np.array(users.loc[users['UserID'] == user_id, 'profile'])[0]\n",
    "    historical_apps = user_history.loc[user_history.UserID == user_id, 'JobTitle']\n",
    "    for application in historical_apps:\n",
    "        user_profile += \". \" + (str(application) + \" \")*1\n",
    "    user_profile = simple_preprocess(user_profile)\n",
    "    \n",
    "    best = 0\n",
    "    top10=pd.DataFrame(index = range(top), columns = ['JobID', 'Title', 'Description', 'Requirements'])\n",
    "    \n",
    "    \n",
    "    for i in range (100):\n",
    "        inferred_vector = model.infer_vector(user_profile, topn=len(model.docvecs))\n",
    "        sims = model.docvecs.most_similar([inferred_vector])\n",
    "        sum_results = 0\n",
    "        \n",
    "        for i in range(top):\n",
    "            sum_results+=sims[i][1]\n",
    "            \n",
    "        if sum_results > best:\n",
    "            best = sum_results\n",
    "            best_sim = sims\n",
    "            \n",
    "            \n",
    "    for i in range(top):\n",
    "        recomendation = jobID_mapping[best_sim[i][0]]\n",
    "        top10.iloc[i] = np.array(jobs.loc[jobs['JobID'] == recomendation][['JobID', 'Title', \n",
    "                                                               'Description', 'Requirements']])[0]\n",
    "    \n",
    "    \n",
    "    return top10, sims\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1041,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "    Degree Type: None\n",
      "    Major: Electrical Engineering\n",
      "    Previous Applications:\n",
      "    \n",
      "Compliance Associate / Temporary Consultant\n",
      "Compliance Associate/ Administrative Specialist\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'248008,\\n 1184529,\\n 1122774,\\n 1165147,\\n 875025,\\n 932674,\\n 563339,\\n 1433717,\\n 944873,\\n 153286,'"
      ]
     },
     "execution_count": 1041,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "user_id = 248008\n",
    "t, s = content_based_recommender(user_id, top=10)\n",
    "print(user_profile(user_id))\n",
    "\n",
    "\"\"\"248008,\n",
    " 1184529,\n",
    " 1122774,\n",
    " 1165147,\n",
    " 875025,\n",
    " 932674,\n",
    " 563339,\n",
    " 1433717,\n",
    " 944873,\n",
    " 153286,\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 948,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0                     ADMINISTRATIVE/CLERICAL\n",
       "1                     ADMINISTRATIVE/CLERICAL\n",
       "2                               GENERAL LABOR\n",
       "3                                          GL\n",
       "4                                          GL\n",
       "5                                          GL\n",
       "6                                          GL\n",
       "7                                          GL\n",
       "8    MEDICAL ASSISTANT / MEDICAL RECEPTIONIST\n",
       "9                     Executive Administrator\n",
       "Name: Title, dtype: object"
      ]
     },
     "execution_count": 948,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t.Title"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 950,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0                                             colating\n",
       "1                                             colating\n",
       "2                                                 none\n",
       "3    westfield ny seasonal openings all shifts with...\n",
       "4    westfield ny seasonal openings all shifts with...\n",
       "5    westfield ny seasonal openings all shifts with...\n",
       "6    westfield ny seasonal openings all shifts with...\n",
       "7    westfield ny seasonal openings all shifts with...\n",
       "8    medical assistant medical receptionistmedical ...\n",
       "9                                                     \n",
       "Name: Description, dtype: object"
      ]
     },
     "execution_count": 950,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t.Description\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1021,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(10091, 0.6514291763305664),\n",
       " (4365, 0.6238051652908325),\n",
       " (10528, 0.6194992065429688),\n",
       " (10625, 0.6180371642112732),\n",
       " (2716, 0.6179522275924683),\n",
       " (723, 0.6152012348175049),\n",
       " (4445, 0.5981876850128174),\n",
       " (8527, 0.5963398218154907),\n",
       " (1772, 0.5838823318481445),\n",
       " (3529, 0.5803802013397217)]"
      ]
     },
     "execution_count": 1021,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 860,
   "metadata": {},
   "outputs": [],
   "source": [
    "def user_profile(user_id):\n",
    "    user_profile = np.array(users.loc[users['UserID'] == user_id, ['DegreeType', 'Major']])[0]\n",
    "    historical_apps = user_history.loc[user_history.UserID == user_id, 'JobTitle']\n",
    "    user_profile = \"\"\"\n",
    "    Degree Type: {}\n",
    "    Major: {}\n",
    "    Previous Applications:\n",
    "    \"\"\".format(user_profile[0], user_profile[1])\n",
    "    \n",
    "    for application in historical_apps:\n",
    "        user_profile += \"\\n\" + str(application)\n",
    "        \n",
    "    return user_profile"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### User to User\n",
    "#### Distance Recommender\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
